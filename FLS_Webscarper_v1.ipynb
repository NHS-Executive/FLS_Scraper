{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwa5b83ZW_BR",
        "outputId": "e3505b11-6029-49d9-9a13-169b0a47cd18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/DXAwithin12weeks?opendocument&org=[All]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/DXAwithin12weeks?opendocument&org=7A2T\n",
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/DXAwithin12weeks?opendocument&org=7A5T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/DXAwithin12weeks?opendocument&org=GWY\n",
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/DXAwithin12weeks?opendocument&org=LLD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/DXAwithin12weeks?opendocument&org=MOR\n",
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/DXAwithin12weeks?opendocument&org=NEV\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/Investigationandtreatment?opendocument&org=[All]\n",
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/Investigationandtreatment?opendocument&org=7A2T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/Investigationandtreatment?opendocument&org=7A5T\n",
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/Investigationandtreatment?opendocument&org=GWY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/Investigationandtreatment?opendocument&org=LLD\n",
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/Investigationandtreatment?opendocument&org=MOR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fffap.org.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/Investigationandtreatment?opendocument&org=NEV\n",
            "---------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "## Import relevant libraries:\n",
        "from bs4 import BeautifulSoup\n",
        "import requests, certifi\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import os\n",
        "import re\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util import Retry\n",
        "\n",
        "def replaceValsWithNationalVals(variable_dict=None, localValsVar=None, nationalValsVar=None):\n",
        "    if any(nationalValsVar in d for d in variable_dict) and not any(localValsVar in d for d in variable_dict):\n",
        "                mnths_dict = next(d for d in variable_dict if nationalValsVar in d)\n",
        "                variable_dict.append({localValsVar: mnths_dict[nationalValsVar]})\n",
        "\n",
        "# setup working directory\n",
        "base_path = '/content/'\n",
        "print('*******')\n",
        "\n",
        "siteList = ['[All]','7A2T','7A5T','GWY','LLD','MOR','NEV']\n",
        "siteHBDict = {\n",
        "    '7A2T': 'HDUHB',\n",
        "    '7A5T': 'CTMUHB',\n",
        "    'GWY': 'BCUHB',\n",
        "    'LLD': 'CAVUHB',\n",
        "    'MOR': 'SBUHB',\n",
        "    'NEV': 'ABUHB',\n",
        "    '[All]': 'All Wales'\n",
        "}\n",
        "ChartList = ['DXAwithin12weeks','Investigationandtreatment']\n",
        "DXA_df = pd.DataFrame()\n",
        "Investigationandtreatment_df = pd.DataFrame()\n",
        "\n",
        "retry_strategy = Retry(\n",
        "    total=4,  # Maximum number of retries\n",
        "    status_forcelist=[429, ## Too Many Requests\n",
        "                      500, ## Internal Server Error\n",
        "                      502, ## 502 Bad Gateway\n",
        "                      503, ## 503 Service Unavailable\n",
        "                      504 ## 504 Gateway Timeout\n",
        "                      ],  # HTTP status codes to retry on\n",
        ")\n",
        "# Create an HTTP adapter with the retry strategy and mount it to session\n",
        "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "\n",
        "date_of_scrape = datetime.now(pytz.timezone(\"Europe/London\"))\n",
        "date_of_scrape = date_of_scrape.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "# Create a new session object\n",
        "session = requests.Session()\n",
        "session.mount('https://', adapter)\n",
        "\n",
        "# Loop through each Site and Chart to scrape data\n",
        "for chart in ChartList:\n",
        "    for site in siteList:\n",
        "        url = f'https://www.fffap.org.uk/FLS/charts.nsf/vwPcharts/{chart}?opendocument&org={site}'\n",
        "        print(url)\n",
        "\n",
        "        result = session.get(\n",
        "            url,\n",
        "            headers={'User-Agent': 'Mozilla/5.0'},\n",
        "            verify=False\n",
        "        )\n",
        "\n",
        "        ## Parse Content of Results Object\n",
        "        doc = BeautifulSoup(result.text, \"html.parser\")\n",
        "\n",
        "        # Find the Numeric data in the html code\n",
        "        data = '\\n'.join(script.text for script in doc.find_all('script', {'type': 'text/javascript'}))\n",
        "        match_scripts = re.findall(r\"(.*)( = )([^;]*)\", data)\n",
        "\n",
        "        # Convert List of Tuples to List of Dictionaries\n",
        "        variable_dict = []\n",
        "        \"\"\"\n",
        "        The 3 part Tuple for each list item will always match the below Index positions:\n",
        "        0 = Javascript variable name (i.e. var cat)\n",
        "        1 = will always be the string '='\n",
        "        2 = the content of the variable.\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "\n",
        "        # Differentiate between [All] sites and individual sites\n",
        "        if site != '[All]':\n",
        "            for variable in match_scripts:\n",
        "                if match_scripts[count][0] in [\n",
        "                                            \"var cats\",\n",
        "                                            \"var dxah\" ,\n",
        "                                            \"var bp\",\n",
        "                                            \"var months\",\n",
        "                                            \"var mnths\",\n",
        "                                            \"var dxan\",\n",
        "                                            \"var bpn\",\n",
        "                                            \"var axa\",\n",
        "                                            \"var falls\",\n",
        "                                            \"var dxa75\",\n",
        "                                            \"var axan\",\n",
        "                                            \"var fallsn\",\n",
        "                                            \"var dxa75n\"\n",
        "                                            ]:\n",
        "                    variable_dict.append({variable[0].strip(): variable[2].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").strip().split(\",\")})\n",
        "                    count += 1\n",
        "                else:\n",
        "                    count += 1\n",
        "                    pass\n",
        "        else:\n",
        "            # For [All] sites, local variables are not available, only national equivalents\n",
        "            for variable in match_scripts:\n",
        "                # Only capture national variables\n",
        "                if match_scripts[count][0] in [\n",
        "                                            \"var mnths\",\n",
        "                                            \"var dxan\",\n",
        "                                            \"var bpn\",\n",
        "                                            \"var axan\",\n",
        "                                            \"var fallsn\",\n",
        "                                            \"var dxa75n\"\n",
        "                                            ]:\n",
        "                    variable_dict.append({variable[0].strip(): variable[2].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").strip().split(\",\")})\n",
        "                    count += 1\n",
        "                else:\n",
        "                    count += 1\n",
        "                    pass\n",
        "\n",
        "            # Fill missing local variables with national equivalents\n",
        "            replaceValsWithNationalVals(variable_dict, 'var cats', 'var mnths')\n",
        "            replaceValsWithNationalVals(variable_dict, 'var dxah', 'var dxan')\n",
        "            replaceValsWithNationalVals(variable_dict, 'var bp', 'var bpn')\n",
        "            replaceValsWithNationalVals(variable_dict, 'var axa', 'var axan')\n",
        "            replaceValsWithNationalVals(variable_dict, 'var falls', 'var fallsn')\n",
        "            replaceValsWithNationalVals(variable_dict, 'var dxa75', 'var dxa75n')\n",
        "\n",
        "        # Convert List of Dictionaries to DataFrame\n",
        "        temp_df = pd.DataFrame()\n",
        "        for var_idx in range(len(variable_dict)):\n",
        "            key = list(variable_dict[var_idx].keys())[0]\n",
        "            ser = pd.Series(variable_dict[var_idx][key])\n",
        "            try:\n",
        "                temp_df.insert(var_idx, key, ser)\n",
        "            except ValueError:\n",
        "                temp_df.insert(var_idx, key + str(var_idx), ser)\n",
        "\n",
        "        # Rename Columns\n",
        "        temp_df.rename(columns={\n",
        "            \"var cats\": \"Date Index Fracture Diagnosed Year & Month (Alt)\",\n",
        "            \"var dxah\": \"Patients where a DXA was ordered or recommended and was completed within 12 weeks %\" ,\n",
        "            \"var bp\": \"Patients offered Bone Protection medication %\",\n",
        "            \"var months\": \"Date Index Fracture Diagnosed Year & Month\",\n",
        "            \"var mnths\": \"Date Index Fracture Diagnosed Year & Month\",\n",
        "            \"var dxan\": \"Patients where a DXA was ordered or recommended and was completed within 12 weeks National %\",\n",
        "            \"var bpn\":\"Bone Protection Meds National %\",\n",
        "            \"var axa\": \"FLS assessment <=90 days %\",\n",
        "            \"var falls\": \"Patients offered/referred for falls risk assessment %\",\n",
        "            \"var dxa75\": \"Patients<75 offered/undergone a DXA %\",\n",
        "            \"var axan\": \"FLS assessment <=90 days National %\",\n",
        "            \"var fallsn\": \"Falls assessment National %\",\n",
        "            \"var dxa75n\":\"Patients<75 offered/undergone a DXA National %\"\n",
        "        }, inplace=True)\n",
        "\n",
        "        # Add SiteNameCode and Healthboard columns\n",
        "        temp_df[\"SiteNameCode\"] = f\"FLS_{site}\"\n",
        "        temp_df[\"Healthboard\"] = siteHBDict[site]\n",
        "        ## Add Date of Scrape column\n",
        "        temp_df[\"Date_of_Scrape\"] = date_of_scrape\n",
        "\n",
        "        # Append to relevant DataFrame\n",
        "        if chart == 'DXAwithin12weeks':\n",
        "            DXA_df = pd.concat([DXA_df, temp_df], ignore_index=True)\n",
        "        elif chart == 'Investigationandtreatment':\n",
        "            Investigationandtreatment_df = pd.concat([Investigationandtreatment_df, temp_df], ignore_index=True)\n",
        "\n",
        "        print(\"---------------------------------------------------\")\n",
        "\n",
        "# Replace blank spaces with NaN in both dataframes\n",
        "DXA_df = DXA_df.replace(r'^\\s*$', pd.NA, regex=True)\n",
        "Investigationandtreatment_df = Investigationandtreatment_df.replace(r'^\\s*$', pd.NA, regex=True)\n",
        "\n",
        "#Reorder Columns for both dataframes\n",
        "Investigationandtreatment_df = Investigationandtreatment_df[[\n",
        "    \"Date Index Fracture Diagnosed Year & Month\",\n",
        "    \"FLS assessment <=90 days %\",\n",
        "    \"FLS assessment <=90 days National %\",\n",
        "    \"Patients offered/referred for falls risk assessment %\",\n",
        "    \"Falls assessment National %\",\n",
        "    \"Patients offered Bone Protection medication %\",\n",
        "    \"Bone Protection Meds National %\",\n",
        "    \"Patients<75 offered/undergone a DXA %\",\n",
        "    \"Patients<75 offered/undergone a DXA National %\",\n",
        "    \"SiteNameCode\",\n",
        "    \"Healthboard\",\n",
        "    \"Date_of_Scrape\"\n",
        "]]\n",
        "DXA_df = DXA_df[[\n",
        "    \"Date Index Fracture Diagnosed Year & Month\",\n",
        "    \"Patients where a DXA was ordered or recommended and was completed within 12 weeks %\",\n",
        "    \"Patients where a DXA was ordered or recommended and was completed within 12 weeks National %\",\n",
        "    \"SiteNameCode\",\n",
        "    \"Healthboard\",\n",
        "    \"Date_of_Scrape\"\n",
        "]]\n",
        "\n",
        "#Directory and file path\n",
        "directory_path = f'FLS_Scrape_{date_of_scrape}'\n",
        "os.makedirs(directory_path, exist_ok=True)\n",
        "\n",
        "dxa_file_path = os.path.join(directory_path, f'{ChartList[0]}.csv')\n",
        "IandT_file_path = os.path.join(directory_path, f'{ChartList[1]}.csv')\n",
        "\n",
        "# Export DataFrames to CSV\n",
        "DXA_df.to_csv(dxa_file_path, encoding='utf-8', index=False)\n",
        "Investigationandtreatment_df.to_csv(IandT_file_path, encoding='utf-8', index=False)\n"
      ]
    }
  ]
}